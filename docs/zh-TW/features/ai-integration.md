# AI 整合

連接多個 AI 供應商，並在整個 PackageFlow 中使用智慧輔助。

## 概覽

PackageFlow 支援多個 AI 供應商用於智慧功能，如：

- 提交訊息產生
- 程式碼分析
- 安全公告摘要
- 自訂 AI 提示

<!-- TODO: Add screenshot of AI settings panel -->

## 支援的供應商

| 供應商 | 模型 | 驗證 |
|--------|------|------|
| **OpenAI** | GPT-3.5、GPT-4、GPT-4 Turbo | API Key |
| **Anthropic** | Claude 3 系列 | API Key |
| **Google** | Gemini Pro、Gemini Ultra | API Key |
| **Ollama** | 任何本地模型 | 本地 |
| **LM Studio** | 任何本地模型 | 本地 |

## 新增 AI 服務

### 雲端供應商（OpenAI、Anthropic、Google）

1. 前往**設定** → **AI 服務**
2. 點擊**新增服務**
3. 選擇供應商
4. 輸入您的 API key
5. 點擊**驗證並儲存**

<!-- TODO: Add screenshot of add service dialog -->

### 本地供應商（Ollama、LM Studio）

1. 確保 Ollama/LM Studio 在本地執行
2. 前往**設定** → **AI 服務**
3. 點擊**新增服務**
4. 選擇 **Ollama** 或 **LM Studio**
5. 輸入本地 URL（預設：`http://localhost:11434`）
6. 點擊**連接**

## API Key 安全

API key 使用 AES-256-GCM 加密並安全儲存：

- Key 永遠不會暴露在日誌中
- 靜態加密
- 儲存在系統 keychain（macOS）

## 選擇模型

### 每個服務的模型

每個服務都有可用模型：

1. 點擊服務
2. 點擊**取得模型**
3. 選擇您偏好的預設模型

### 每個功能的模型

為不同任務選擇不同模型：

- 提交訊息：較快的模型（GPT-3.5）
- 程式碼審查：更強大的模型（GPT-4）

## AI 功能

### 提交訊息產生

從您的差異產生有意義的提交訊息：

1. 暫存您的變更
2. 點擊提交表單中的 **AI** 按鈕
3. AI 分析差異並產生訊息
4. 需要時編輯，然後提交

<!-- TODO: Add gif of AI commit message generation -->

### 程式碼分析（即將推出）

AI 驅動的程式碼審查建議。

### 安全摘要（即將推出）

安全漏洞的白話解釋。

## 提示範本

使用範本自訂 AI 產生內容的方式。

### 預設範本

PackageFlow 包含以下範本：

- Git 提交訊息
- Pull request 描述
- 程式碼審查評論
- 發布說明
- 安全公告
- 自訂

### 建立自訂範本

1. 前往**設定** → **AI 服務** → **範本**
2. 點擊**新增範本**
3. 設定：
   - 名稱
   - 類別
   - 帶變數的提示文字
4. 儲存

<!-- TODO: Add screenshot of template editor -->

### 範本變數

在提示中使用變數：

| 變數 | 說明 |
|------|------|
| `{diff}` | Git 差異內容 |
| `{code}` | 選中的程式碼 |
| `{file_path}` | 目前檔案路徑 |
| `{language}` | 檔案語言 |
| `{project_name}` | 專案名稱 |

### 範本範例

**提交訊息範本：**

```
根據以下 git diff，產生遵循 conventional commit 格式的簡潔提交訊息。

重點：
- 變更了什麼（而非如何）
- 為什麼變更（如果明顯）
- 第一行保持在 72 個字元以下

Diff：
{diff}
```

### 專案範本

為特定專案覆寫範本：

1. 開啟專案
2. 前往**設定** → **AI**
3. 選擇範本覆寫
4. 根據需要自訂

## 測試服務

### 連接測試

驗證您的 API key 有效：

1. 點擊服務上的**測試連接**
2. PackageFlow 發送簡單請求
3. 顯示成功或錯誤詳情

### 延遲測試

檢查回應時間：

1. 點擊**測試延遲**
2. 計時多個請求
3. 顯示平均延遲

<!-- TODO: Add screenshot of latency test results -->

## 預設服務

設定預設 AI 服務：

1. 前往**設定** → **AI 服務**
2. 點擊服務旁的星號圖示
3. 此服務在未特別指定時使用

## 使用限制

### 雲端供應商

注意 API 速率限制和成本：

- OpenAI：按 token 計費
- Anthropic：按 token 計費
- Google：有免費層

### 本地供應商

本地執行時無限制：

- Ollama：無限制
- LM Studio：無限制

## 提示

1. **從 GPT-3.5 開始**：對大多數任務來說快速且便宜
2. **使用本地模型**：對於敏感程式碼，使用 Ollama
3. **自訂範本**：更好的提示 = 更好的結果
4. **測試連接**：在依賴 AI 功能前驗證 API key 有效
5. **監控成本**：雲端 API 呼叫會快速累積

## 疑難排解

### API Key 無效

- 驗證 key 正確
- 檢查 key 是否有必要權限
- 確保帳單已啟用（雲端供應商）

### 回應緩慢

- 嘗試較小/較快的模型
- 檢查網路連接
- 考慮使用本地模型以獲得更快回應

### 輸出品質差

- 檢視並改進您的提示範本
- 嘗試更強大的模型
- 在範本中提供更多上下文
